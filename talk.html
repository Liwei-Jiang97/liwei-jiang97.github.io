<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="site.css" />
  <title> Liwei Jiang </title>
</head>

<body>

  <header>
    <h1> Liwei Jiang </h1>
    <nav>
      <ul>
        <li><a href="index.html"> Home </a></li>
        <li><a href="publication.html"> Publications</a> </li>
        <li><a href="talk.html"> Talks</a> </li>
        <li><a href="teaching.html"> Teaching </a></li>
      </ul>
    </nav>
  </header>


  <main>
    <h2> Talks </h2>
    <!-- Fill in the content below-->
         <div class="paper">
      <h4>Gradient descent with adaptive stepsize converges (nearly) linearly under fourth-order growth</h4>
      <p>International Conference on Continuous Optimization, 7/2025</p>
    </div>
    
             <div class="paper">
      <h4>A local nearly linearly convergent gradient method for "typical" nonsmooth functions</h4>
      <p>Informs, 10/2024</p>
      <p>UCSD ECE, SOC Lab, 2/2024</p>
    </div>
            <div class="paper">
      <h4>Asymptotic normality in nonsmooth optimization</h4>
      <p>Informs award session, 10/2024</p>
      <p> International Symposium on Mathematical Programming, 07/2024 </p> 
      <p>Informs, 10/2023
      <p>Cornell Young Researcher Workshop, 10/2023</p>
    </div>
        <div class="paper">
      <h4>Subgradient methods avoid strict saddle point</h4>
      <p>SIAM Conference on Optimization, 6/2023</p>
      <p>International Conference on Continuous Optimization, 7/2022</p>
    </div>
    <div class="paper">
      <h4>Rank overspecified robust matrix recovery: Subgradient method and exact recovery</h4>
      <p>Informs, 10/2021</p>
    </div>

  </main>

  <footer>
    <p> All content copyright &copy; 2024 </p>
  </footer>


</body>

</html>
